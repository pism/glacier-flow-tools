{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7dd5df-edd1-4e40-b83a-7ee663146c29",
   "metadata": {},
   "source": [
    "# Ice-thickness length scale smoothing\n",
    "\n",
    "We are implmenting eq 2 and 3 from https://polarresearch.net/index.php/polar/article/view/3498/9172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c1bebf-42cd-48cf-a7bb-669237385cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter, generic_filter\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcb1d1-aa7a-4308-ad96-7b706c7ffc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cf_xarray.units  # pylint: disable=unused-import\n",
    "import geopandas as gp\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pint_xarray  # pylint: disable=unused-import\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from matplotlib import cm, colors\n",
    "from matplotlib.colors import LightSource\n",
    "from shapely import get_coordinates\n",
    "\n",
    "from glacier_flow_tools.utils import (\n",
    "    blend_multiply,\n",
    "    figure_extent,\n",
    "    get_dataarray_extent,\n",
    "    register_colormaps,\n",
    ")\n",
    "\n",
    "register_colormaps()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d14042-3ef9-404f-81b6-4ce0af8bc28a",
   "metadata": {},
   "source": [
    "## This plotting function makes a nice hillshade so it's easier to validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33add49-a58a-45b4-85e0-17f86ec8a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_glacier(\n",
    "    surface: xr.DataArray,\n",
    "    overlay: xr.DataArray,\n",
    "    cmap: str = \"viridis\",\n",
    "    vmin: float = 10,\n",
    "    vmax: float = 1500,\n",
    "    ticks: Union[List[float], np.ndarray] = [10, 100, 250, 500, 750, 1500],\n",
    "    fontsize: float = 6,\n",
    "    figwidth: float = 3.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a surface over a hillshade, add profile and correlation coefficient.\n",
    "\n",
    "    This function plots a surface over a hillshade, adds a profile and correlation coefficient.\n",
    "    The plot is saved as a PDF file in the specified result directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    surface : xr.DataArray\n",
    "        The surface to be plotted over the hillshade.\n",
    "    overlay : xr.DataArray\n",
    "        The overlay to be added to the plot.\n",
    "    result_dir : Union[str, Path]\n",
    "        The directory where the result PDF file will be saved.\n",
    "    cmap : str, optional\n",
    "        The colormap to be used for the plot, by default \"viridis\".\n",
    "    vmin : float, optional\n",
    "        The minimum value for the colormap, by default 10.\n",
    "    vmax : float, optional\n",
    "        The maximum value for the colormap, by default 1500.\n",
    "    ticks : Union[List[float], np.ndarray], optional\n",
    "        The ticks to be used for the colorbar, by default [10, 100, 250, 500, 750, 1500].\n",
    "    fontsize : float, optional\n",
    "        The font size to be used for the plot, by default 6.\n",
    "    figwidth : float, optional\n",
    "        The width of the figure in inches, by default 3.2.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> plot_glacier(profile_series, surface, overlay, '/path/to/result_dir')\n",
    "    \"\"\"\n",
    "    plt.rcParams[\"font.size\"] = fontsize\n",
    "    cartopy_crs = ccrs.NorthPolarStereo(central_longitude=-45, true_scale_latitude=70, globe=None)\n",
    "    # Shade from the northwest, with the sun 45 degrees from horizontal\n",
    "    light_source = LightSource(azdeg=315, altdeg=45)\n",
    "    glacier_overlay = overlay\n",
    "    glacier_surface = surface.interp_like(glacier_overlay)\n",
    "\n",
    "    extent = get_dataarray_extent(glacier_overlay)\n",
    "    norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "    v = mapper.to_rgba(glacier_overlay.to_numpy())\n",
    "    z = glacier_surface.to_numpy()\n",
    "\n",
    "    ar = 1.0  # initial aspect ratio for first trial\n",
    "    wi = figwidth  # width in inches\n",
    "    hi = wi * ar  # height in inches\n",
    "\n",
    "    fig = plt.figure(figsize=(wi, hi))\n",
    "    ax = fig.add_subplot(111, projection=cartopy_crs)\n",
    "    rgb = light_source.shade_rgb(v, elevation=z, vert_exag=0.01, blend_mode=blend_multiply)\n",
    "    # Use a proxy artist for the colorbar...\n",
    "    im = ax.imshow(v, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    im.remove()\n",
    "    ax.imshow(rgb, extent=extent, origin=\"upper\", transform=cartopy_crs)\n",
    "    ax.gridlines(\n",
    "        draw_labels={\"top\": \"x\", \"left\": \"y\"},\n",
    "        dms=True,\n",
    "        xlocs=np.arange(-50, 0, 1),\n",
    "        ylocs=np.arange(50, 88, 1),\n",
    "        x_inline=False,\n",
    "        y_inline=False,\n",
    "        rotate_labels=20,\n",
    "        ls=\"dotted\",\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "    fig.colorbar(im, ax=ax, shrink=0.5, pad=0.025, label=overlay.units, extend=\"both\", ticks=ticks)\n",
    "    plt.draw()\n",
    "\n",
    "    # Get proper ratio here\n",
    "    xmin, xmax = ax.get_xbound()\n",
    "    ymin, ymax = ax.get_ybound()\n",
    "    y2x_ratio = (ymax - ymin) / (xmax - xmin)\n",
    "    fig.set_figheight(wi * y2x_ratio)\n",
    "    fig.tight_layout()\n",
    "    plt.close()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1e251-5cd8-438f-bc7b-954be990aae1",
   "metadata": {},
   "source": [
    "## We use Bedmachine as it has both surface and ice thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898c5ff-0226-4e6f-8e9a-abf7bccba346",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"/mnt/storstrommen/data/MCdataset/BedMachineGreenland-v5.nc\")\n",
    "# ds = xr.open_dataset(\"/Users/andy/Google Drive/My Drive/data/MCdataset/BedMachineGreenland-v5.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d2aadc-b822-4fe5-bbc6-d476ecf8a469",
   "metadata": {},
   "source": [
    "## Select Jakobshavn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b030608-789e-4a3c-b189-2846fe95ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "jak_ds = ds.sel(x=slice(-226_000, -140_000), y=slice(-2_250_000, -2_300_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde9da1-50db-4a6a-ad59-4ef9521d9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = jak_ds[\"surface\"]\n",
    "plot_glacier(dem, dem, cmap=\"Grays\", figwidth=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecd8b3-b65c-4f9f-a236-a7763a45d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_smoothed_gaussian = jak_ds[\"surface\"].copy()\n",
    "dem_smoothed_gaussian.values = gaussian_filter(jak_ds[\"surface\"], 2)\n",
    "plot_glacier(dem_smoothed_gaussian, dem_smoothed_gaussian, cmap=\"Grays\", figwidth=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc72c2-e58f-4575-b6de-18548b2a96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = jak_ds[\"thickness\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c595f78-0912-4df7-b152-fd637eb2aa73",
   "metadata": {},
   "source": [
    "## Brinkerhoff, Aschwanden and Fahnestock (2021): DOI:10.1017/jog.2020.112\n",
    "\n",
    "I think Eq 45 should give us a distance scaled sigma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a076182-0572-4c7c-b18e-1a93f3ad1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 4  # length scale\n",
    "L = l * (H.to_numpy() @ H.to_numpy().T)**(1/2) # I am not sure this is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad2949-f9fd-4fcc-8f1d-cfa09db65169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662abbdc-8788-464b-82c7-1d4807231baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(H.x, H.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16730aba-8771-40e5-8c74-a9c9ad01cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = squareform(pdist(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e8c71-3fdb-4023-8ad4-127dcfd9cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = (1 + D**2 / (2 * L**2))**(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdac6704-0089-4413-b26a-a003699786a1",
   "metadata": {},
   "source": [
    "## Gaussian smoothing\n",
    "\n",
    "$$ \\omega=\\frac{1}{2 \\pi \\sigma^2} e^{-\\frac{x^2+y^2}{2 \\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe11450-6867-4d1a-9577-edb1a8210cab",
   "metadata": {},
   "source": [
    "How do we implment this as a **generic_filter**? The implementation of **gaussian_filter** is here: https://github.com/scipy/scipy/blob/v1.13.1/scipy/ndimage/_filters.py#L286-L390.\n",
    "It uses *np.correlate* instead of convolve, and loops over all axis. Can we do that too?\n",
    "\n",
    "Maybe we can use https://github.com/scipy/scipy/blob/v1.13.1/scipy/ndimage/_filters.py#L186 for inspiration. We need to compute $\\sigma$ scaled by ice thickness in a sensible way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d6277-505b-486f-af5c-1f1609724c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_weighted_filter(dem, l, H, radius):\n",
    "    x = np.arange(-radius, radius+1)\n",
    "    L = l * (H @ H.T)**(1/2) # I am not sure this is correct\n",
    "    D = squareform(pdist(np.vstack([x.ravel(), x.ravel()]).T))\n",
    "    sigma = (1 + D**2 / (2 * L**2))**(-1)\n",
    "    phi = 1 / (2 * np.pi * sigma**2) * np.exp(-(x**2 + y**2) / (2 * sigma**2) )\n",
    "    return np.correlate(dem, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7d7e3-b4c9-4e06-b678-c31a41096fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem = jak_ds[\"surface\"].to_numpy()\n",
    "H = jak_ds[\"thickness\"].to_numpy()\n",
    "x = jak_ds.x.to_numpy()\n",
    "y = jak_ds.y.to_numpy()\n",
    "X, Y = np.meshgrid(x, y)\n",
    "l = 4\n",
    "m, n = dem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aca0c2-c999-4524-87ee-d8c3d750119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    L = l * (H @ H.T)**(1/2) # I am not sure this is correct\n",
    "    X_dist = np.zeros((m*n, 2))\n",
    "    X_dist[:, 0] = X.ravel()\n",
    "    X_dist[:, 1] = Y.ravel()\n",
    "    D = squareform(pdist(X_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa33d04-5923-4194-9c5d-d529870d68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-Pilot \n",
    "import numpy as np\n",
    "from scipy.ndimage import generic_filter\n",
    "\n",
    "def gaussian(x, sigma):\n",
    "    \"\"\"\n",
    "    Gaussian function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float\n",
    "        The distance from the center of the Gaussian.\n",
    "    sigma : float\n",
    "        The standard deviation of the Gaussian.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The value of the Gaussian function at x.\n",
    "    \"\"\"\n",
    "    return (1 / (2 * np.pi * sigma**2)) * np.exp(-x**2 / (2 * sigma**2))\n",
    "\n",
    "def apply_gaussian_filter(input_array, sigma):\n",
    "    \"\"\"\n",
    "    Apply a Gaussian filter to an array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_array : numpy.ndarray\n",
    "        The input array to filter.\n",
    "    sigma : float\n",
    "        The standard deviation of the Gaussian filter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The filtered array.\n",
    "    \"\"\"\n",
    "    # Define the footprint of the filter to be the same size as the input array\n",
    "    footprint = np.ones_like(input_array)\n",
    "\n",
    "    # Define the function to apply to each neighborhood\n",
    "    def func(neighborhood):\n",
    "        # Calculate the distances from the center\n",
    "        distances = np.abs(neighborhood - neighborhood[len(neighborhood) // 2])\n",
    "        # Apply the Gaussian function to each distance\n",
    "        return gaussian(distances, sigma)\n",
    "\n",
    "    # Apply the filter\n",
    "    return generic_filter(input_array, func, footprint=footprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b5b5e-c800-4ab8-820a-4fd8e055ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too much memory\n",
    "apply_gaussian_filter(dem, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e19cb4-64bd-4024-a05a-45439ada7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gaussian_weighted_kernel1d(l, H, x):\n",
    "    \"\"\"\n",
    "    Computes a 1-D ice-thickness weighted Gaussian convolution kernel.\n",
    "    \"\"\"\n",
    "\n",
    "    L = l * (H @ H.T)**(1/2) # I am not sure this is correct\n",
    "    sigma = (1 + D**2 / (2 * L**2))**(-1)\n",
    "    sigma2 = sigma * sigma\n",
    "    phi_x = numpy.exp(-0.5 / sigma2 * x ** 2)\n",
    "    phi_x = phi_x / phi_x.sum()\n",
    "\n",
    "    return phi_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707bfde1-f8b0-497e-b984-9f192d3b3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_weighted_filter1d(input, l, H, x, axis=-1, order=0, output=None,\n",
    "                      mode=\"reflect\", cval=0.0):\n",
    "    \"\"\"1-D Gaussian filter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    %(input)s\n",
    "    l : number of ice thicknesses\n",
    "        ice thickness multiplier\n",
    "    %(axis)s\n",
    "    order : int, optional\n",
    "        An order of 0 corresponds to convolution with a Gaussian\n",
    "        kernel. A positive order corresponds to convolution with\n",
    "        that derivative of a Gaussian.\n",
    "    %(output)s\n",
    "    %(mode_reflect)s\n",
    "    %(cval)s\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gaussian_weighted_filter1d : ndarray\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    sd = float(sigma)\n",
    "    # make the radius of the filter equal to truncate standard deviations\n",
    "    lw = int(truncate * sd + 0.5)\n",
    "    if radius is not None:\n",
    "        lw = radius\n",
    "    if not isinstance(lw, numbers.Integral) or lw < 0:\n",
    "        raise ValueError('Radius must be a nonnegative integer.')\n",
    "    # Since we are calling correlate, not convolve, revert the kernel\n",
    "    weights = _gaussian_weighted_kernel1d(l, H, x)[::-1]\n",
    "    return correlate1d(input, weights, axis, output, mode, cval, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee43d50-da19-41aa-a2b6-cdc447223e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_weighted_filter(input, l, H, x, output=None,\n",
    "                    mode=\"reflect\", cval=0.0,\n",
    "                    axes=None):\n",
    "    \"\"\"Multidimensional Gaussian filter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    %(input)s\n",
    "    sigma : scalar or sequence of scalars\n",
    "        Standard deviation for Gaussian kernel. The standard\n",
    "        deviations of the Gaussian filter are given for each axis as a\n",
    "        sequence, or as a single number, in which case it is equal for\n",
    "        all axes.\n",
    "    order : int or sequence of ints, optional\n",
    "        The order of the filter along each axis is given as a sequence\n",
    "        of integers, or as a single number. An order of 0 corresponds\n",
    "        to convolution with a Gaussian kernel. A positive order\n",
    "        corresponds to convolution with that derivative of a Gaussian.\n",
    "    %(output)s\n",
    "    %(mode_multiple)s\n",
    "    %(cval)s\n",
    "    truncate : float, optional\n",
    "        Truncate the filter at this many standard deviations.\n",
    "        Default is 4.0.\n",
    "    radius : None or int or sequence of ints, optional\n",
    "        Radius of the Gaussian kernel. The radius are given for each axis\n",
    "        as a sequence, or as a single number, in which case it is equal\n",
    "        for all axes. If specified, the size of the kernel along each axis\n",
    "        will be ``2*radius + 1``, and `truncate` is ignored.\n",
    "        Default is None.\n",
    "    axes : tuple of int or None, optional\n",
    "        If None, `input` is filtered along all axes. Otherwise,\n",
    "        `input` is filtered along the specified axes. When `axes` is\n",
    "        specified, any tuples used for `sigma`, `order`, `mode` and/or `radius`\n",
    "        must match the length of `axes`. The ith entry in any of these tuples\n",
    "        corresponds to the ith entry in `axes`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gaussian_filter : ndarray\n",
    "        Returned array of same shape as `input`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The multidimensional filter is implemented as a sequence of\n",
    "    1-D convolution filters. The intermediate arrays are\n",
    "    stored in the same data type as the output. Therefore, for output\n",
    "    types with a limited precision, the results may be imprecise\n",
    "    because intermediate results may be stored with insufficient\n",
    "    precision.\n",
    "\n",
    "    The Gaussian kernel will have size ``2*radius + 1`` along each axis. If\n",
    "    `radius` is None, the default ``radius = round(truncate * sigma)`` will be\n",
    "    used.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from scipy.ndimage import gaussian_filter\n",
    "    >>> import numpy as np\n",
    "    >>> a = np.arange(50, step=2).reshape((5,5))\n",
    "    >>> a\n",
    "    array([[ 0,  2,  4,  6,  8],\n",
    "           [10, 12, 14, 16, 18],\n",
    "           [20, 22, 24, 26, 28],\n",
    "           [30, 32, 34, 36, 38],\n",
    "           [40, 42, 44, 46, 48]])\n",
    "    >>> gaussian_filter(a, sigma=1)\n",
    "    array([[ 4,  6,  8,  9, 11],\n",
    "           [10, 12, 14, 15, 17],\n",
    "           [20, 22, 24, 25, 27],\n",
    "           [29, 31, 33, 34, 36],\n",
    "           [35, 37, 39, 40, 42]])\n",
    "\n",
    "    >>> from scipy import datasets\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> fig = plt.figure()\n",
    "    >>> plt.gray()  # show the filtered result in grayscale\n",
    "    >>> ax1 = fig.add_subplot(121)  # left side\n",
    "    >>> ax2 = fig.add_subplot(122)  # right side\n",
    "    >>> ascent = datasets.ascent()\n",
    "    >>> result = gaussian_filter(ascent, sigma=5)\n",
    "    >>> ax1.imshow(ascent)\n",
    "    >>> ax2.imshow(result)\n",
    "    >>> plt.show()\n",
    "    \"\"\"\n",
    "    input = numpy.asarray(input)\n",
    "    output = _ni_support._get_output(output, input)\n",
    "\n",
    "    axes = _ni_support._check_axes(axes, input.ndim)\n",
    "    num_axes = len(axes)\n",
    "    orders = _ni_support._normalize_sequence(order, num_axes)\n",
    "    sigmas = _ni_support._normalize_sequence(sigma, num_axes)\n",
    "    modes = _ni_support._normalize_sequence(mode, num_axes)\n",
    "    radiuses = _ni_support._normalize_sequence(radius, num_axes)\n",
    "    axes = [(axes[ii], sigmas[ii], orders[ii], modes[ii], radiuses[ii])\n",
    "            for ii in range(num_axes) if sigmas[ii] > 1e-15]\n",
    "    if len(axes) > 0:\n",
    "        for axis, sigma, order, mode, radius in axes:\n",
    "            gaussian_weighted_filter1d(input, l, H, x, axis, output,\n",
    "                              mode, cval)\n",
    "            input = output\n",
    "    else:\n",
    "        output[...] = input[...]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca7e41-2e62-4576-8996-13b25bafa88d",
   "metadata": {},
   "source": [
    "## Triangular smoothing\n",
    "\n",
    "$$ \\omega = \\max\\left( \\frac{\\sqrt{x^2+y^2}}{\\sigma},0 \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af63265-8c5b-4e7e-b4fa-86cf6803d122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e6cb3-5752-4513-92c4-649cb195f4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d0802b-22f4-40db-bb09-f5d443ccd645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc007bbe-44d6-4d4d-aef7-3cacf88405ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
